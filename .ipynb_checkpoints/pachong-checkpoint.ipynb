{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nlink = soup.find(\"div\", class_=\"sr_item_main_block\")\\nlink2 = link.find(\\'a\\',class_=\\'hotel_name_link url\\')\\nstr1 = \\'https://www.booking.com\\'\\nstr2 = link2.get(\\'href\\')\\n#str2 = str2[2:]\\nstr2 = str2.replace(\"\\r\",\"\")\\nstr2 = str2.replace(\"\\n\",\"\")\\n#url1 = str1 +\\'/\\' +str2\\nurl1 = str1 + str2\\n#print (url1)\\nresponse =requests.get(url1)\\n#print(response.status_code)\\npage = response.text\\n#print (page)\\nsoup2=BeautifulSoup(page,\\'html.parser\\')\\n#a = soup2.find(\"streetAddress\")\\n#print (soup2.prettify())\\n#a = soup2.find(\\'scr\\', class_ =\"bui-review-score__badge\")\\ndata = json.loads(soup2.find(\\'script\\', type=\\'application/ld+json\\').text)\\nprint (data[\\'address\\'][\\'streetAddress\\'])\\n\\n\\nfor link in soup.find_all(\"div\", class_=\"sr_item_main_block\"):\\n        link2 = link.find(\\'a\\',class_=\\'hotel_name_link url\\')\\n  #  print(link.get(\\'href\\'))\\n  # search for hotelwebsite and get value from header\\n        str1 = \\'https://www.booking.com\\'\\n        str2 = link2.get(\\'href\\')\\n        #str2 = str2[2:]\\n        str2 = str2.replace(\"\\r\",\"\")\\n        str2 = str2.replace(\"\\n\",\"\")\\n        #url1 = str1 +\\'/\\' +str2\\n        url1 = str1 + str2\\n        #print (url1)\\n        response =requests.get(url1)\\n        #print(response.status_code)\\n        page = response.text\\n        #print (page)\\n        soup2=BeautifulSoup(page,\\'html.parser\\')\\n        #a = soup2.find(\"streetAddress\")\\n        #print (soup2.prettify())\\n        #a = soup2.find(\\'scr\\', class_ =\"bui-review-score__badge\")\\n        data = json.loads(soup2.find(\\'script\\', type=\\'application/ld+json\\').text)\\n        print (\"name: \"+ data[\\'name\\'])\\n        print (\"Address: \" + data[\\'address\\'][\\'streetAddress\\'])\\n        print (\"type: \" + data[\\'@type\\'])\\n        try:\\n                    rating = str(data[\\'aggregateRating\\'][\\'ratingValue\\'])\\n                    \\n        except:\\n                    rating=\\'na\\'\\n        print (\"ratingValue: \" + rating)\\n        \\n '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import math\n",
    "driver = webdriver.Chrome()\n",
    "#options = webdriver.ChromeOptions()\n",
    "#options.add_argument('headless')\n",
    "\n",
    "#driver = webdriver.Chrome(chrome_options=options)\n",
    "\n",
    "\n",
    "#driver = webdriver.Chrome(r'C:\\Users\\lklio\\Documents\\ai\\chromedriver_win32\\chromedriver.exe') \n",
    "driver.get('https://www.booking.com')\n",
    "\n",
    "\n",
    "\n",
    "driver.find_element_by_id('ss').send_keys(\"Las Vegas\")\n",
    "#WebDriverWait(driver, 1, poll_frequency=0.1).\\\n",
    " #   until(lambda drv: len(drv.find_elements_by_css_selector(\"ul.ui-autocomplete li\")) > 0)\n",
    "#driver.find_element_by_css_selector(\"ul.ui-autocomplete li\").click()\n",
    "#driver.find_element_by_css_selector(\"#availcheck\").click()\n",
    "driver.find_element_by_class_name(\"sb-searchbox__button\").click()\n",
    "\n",
    "WebDriverWait(driver, 10).until(lambda d: d.execute_script('return document.readyState') == 'complete')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "headers = {\n",
    "\"User-Agent\":\n",
    "    \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36\"\n",
    "}\n",
    "\n",
    "s = requests.session()\n",
    "s.headers.update(headers)\n",
    "#pass cookie to requests\n",
    "for cookie in driver.get_cookies():\n",
    "    c = {cookie['name']: cookie['value']}\n",
    "    s.cookies.update(c)\n",
    "\n",
    "\n",
    "html = driver.page_source\n",
    "\n",
    "#html = driver.current_url \n",
    "#print(html)\n",
    "soup=BeautifulSoup(html,'html.parser')\n",
    "#print(soup.title)\n",
    "\n",
    "indexconta = []\n",
    "pagenum = soup.find_all('li',class_='bui-pagination__item sr_pagination_item')\n",
    "for num in pagenum:       #find page number\n",
    "    index = num.find('div',class_='bui-u-inline')\n",
    "    index = index.get_text()\n",
    "    index = int(index)\n",
    "    indexconta.append(index)\n",
    "    \n",
    "print(max(indexconta))\n",
    "\n",
    "\"\"\"\n",
    "link = soup.find(\"div\", class_=\"sr_item_main_block\")\n",
    "link2 = link.find('a',class_='hotel_name_link url')\n",
    "str1 = 'https://www.booking.com'\n",
    "str2 = link2.get('href')\n",
    "#str2 = str2[2:]\n",
    "str2 = str2.replace(\"\\r\",\"\")\n",
    "str2 = str2.replace(\"\\n\",\"\")\n",
    "#url1 = str1 +'/' +str2\n",
    "url1 = str1 + str2\n",
    "#print (url1)\n",
    "response =requests.get(url1)\n",
    "#print(response.status_code)\n",
    "page = response.text\n",
    "#print (page)\n",
    "soup2=BeautifulSoup(page,'html.parser')\n",
    "#a = soup2.find(\"streetAddress\")\n",
    "#print (soup2.prettify())\n",
    "#a = soup2.find('scr', class_ =\"bui-review-score__badge\")\n",
    "data = json.loads(soup2.find('script', type='application/ld+json').text)\n",
    "print (data['address']['streetAddress'])\n",
    "\n",
    "\n",
    "for link in soup.find_all(\"div\", class_=\"sr_item_main_block\"):\n",
    "        link2 = link.find('a',class_='hotel_name_link url')\n",
    "  #  print(link.get('href'))\n",
    "  # search for hotelwebsite and get value from header\n",
    "        str1 = 'https://www.booking.com'\n",
    "        str2 = link2.get('href')\n",
    "        #str2 = str2[2:]\n",
    "        str2 = str2.replace(\"\\r\",\"\")\n",
    "        str2 = str2.replace(\"\\n\",\"\")\n",
    "        #url1 = str1 +'/' +str2\n",
    "        url1 = str1 + str2\n",
    "        #print (url1)\n",
    "        response =requests.get(url1)\n",
    "        #print(response.status_code)\n",
    "        page = response.text\n",
    "        #print (page)\n",
    "        soup2=BeautifulSoup(page,'html.parser')\n",
    "        #a = soup2.find(\"streetAddress\")\n",
    "        #print (soup2.prettify())\n",
    "        #a = soup2.find('scr', class_ =\"bui-review-score__badge\")\n",
    "        data = json.loads(soup2.find('script', type='application/ld+json').text)\n",
    "        print (\"name: \"+ data['name'])\n",
    "        print (\"Address: \" + data['address']['streetAddress'])\n",
    "        print (\"type: \" + data['@type'])\n",
    "        try:\n",
    "                    rating = str(data['aggregateRating']['ratingValue'])\n",
    "                    \n",
    "        except:\n",
    "                    rating='na'\n",
    "        print (\"ratingValue: \" + rating)\n",
    "        \n",
    " \"\"\"       \n",
    "   \n",
    "       # page = response.text\n",
    "   \n",
    "       # soup2=BeautifulSoup(page,'html.parser')\n",
    "       # a = soup2.find('div', class_ =\"bui-review-score__badge\")\n",
    "    \n",
    "    #soup2.find('span', id_=\"b_tt_holder_1\", data-node_tt_id_=\"location_score_tooltip\")\n",
    "      #  location = soup2.get_text()\n",
    "      #  print(location)\n",
    "    \n",
    "\n",
    "\n",
    "#for link in driver.find_elements_by_id(\"hotellist_inner\"):\n",
    "  #  print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "            for div in divs:\n",
    "                info1=div.find('span',{'class':{'sr-hotel__name'}})\n",
    "                name=info1.text.strip()  #店名\n",
    "                try:\n",
    "                    info2=div.find('span',{'class':{'china_stars_categories_title'}})\n",
    "                    style=info2.text.strip()  #类型\n",
    "                except:\n",
    "                    style='未知'\n",
    "                level=div['data-class']  #等级\n",
    "                score=div['data-score']  #得分\n",
    "                if score=='':\n",
    "                    score='未知'\n",
    "                info3=div.find('div',{'class':{'address'}})\n",
    "                address=info3.text.strip().replace('\\n','')  #地址\n",
    "                info4=div.find('div',{'class':{'hotel_desc'}})\n",
    "                desc=info4.text.strip()  #简介\n",
    "                with open('Booking_南京_面向对象.txt','a+',encoding='utf8')as f:\n",
    "                    f.write('店名：'+name+'\\n')\n",
    "                    f.write('类型：'+style+'\\n')\n",
    "                    f.write('等级：'+level+'\\n')\n",
    "                    f.write('得分：'+score+'\\n')\n",
    "                    f.write('地址：'+address+'\\n')\n",
    "                    f.write('简介：'+desc+'\\n')\n",
    "                    f.write('\\n')\n",
    "                f.close()\n",
    "                print('{}-----(*￣︶￣)'.format(name))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdpf\n"
     ]
    }
   ],
   "source": [
    "str1 = 'sd'\n",
    "str2 = 'pf'\n",
    "str3 = str1 + str2\n",
    "print(str3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
